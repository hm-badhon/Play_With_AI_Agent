# ğŸ¦ Intelligent Banking Chatbot

A professional, real-time **AI-powered banking assistant** built using **LangChain**, **FAISS**, **HuggingFace embeddings**, **FastAPI**, and **Streamlit**. 
This chatbot delivers instant, accurate answers to customer queries based on a custom FAQ dataset.

## ğŸš€ Features

- ğŸ§  **Retrieval-Augmented Generation (RAG)** using LangChain
- ğŸ“„ Custom FAQ dataset in **JSON** format
- ğŸ—ƒï¸ Vector search with **FAISS**
- ğŸ’¬ Natural language responses using **Ollama LLM (LLaMA3)**
- ğŸ§¾ Clear, concise, direct answers
- ğŸ›¡ï¸ **Rate limiting** with SlowAPI
- ğŸŒ **CORS support** for frontend-backend communication
- ğŸ›ï¸ **Streamlit frontend UI**
- âš¡ FastAPI-based backend server

## ğŸ“ Project Structure
```python
banking_chatbot/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ banking_faq.json # Preprocessed JSON FAQ data
â”œâ”€â”€ vectorstore/ # FAISS index saved locally
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ backend/
â”‚ â”‚ â”œâ”€â”€ main.py # FastAPI app
â”‚ â”‚ â””â”€â”€ rag_chain.py # Core logic (vector store + LLM + QA)
â”‚ â”œâ”€â”€ frontend/
â”‚ â”‚ â””â”€â”€ ui.py # Streamlit app
â”œâ”€â”€ app.log # Log file
â”œâ”€â”€ create_vectorstore.py # Script to create vector DB from JSON
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md
```

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/banking-chatbot.git
cd banking-chatbot

2. Create and Activate a Virtual Environment

3. Install Dependencies

    pip install -r requirements.txt

4. Create Vector Store from JSON:
    Make sure your banking_faq.json file is placed in the data/ directory.
    # Run script
    python create_vectorstore.py
5. Run FastAPI Backend
    cd app/backend
    uvicorn main:app --reload --port 8000
6. Run Streamlit Frontend
    In another terminal:
        cd app/frontend
        streamlit run ui.py
```

### ğŸ”’ Environment Variables (Optional)
You can define a .env file or export these:
```bash
    EMBEDDING_MODEL=all-MiniLM-L6-v2
    LLM_MODEL=llama3.1:8b
    FAQ_JSON_PATH=data/banking_faq.json
    VECTOR_STORE_PATH=vectorstore
    BACKEND_URL=http://localhost:8000/chat
    FRONTEND_URL=http://localhost:8501
```
### ğŸ“¦ Requirements
Python 3.9+

Ollama installed and running LLaMA3 or similar

GPU support (optional but recommended for embeddings)
